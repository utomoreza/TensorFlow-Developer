{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Course 3 - Week 4 - Lesson 1 - Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwsuGQQY9OL"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRnDnCW-Z7qv",
        "outputId": "f6f8d48f-8df5-47b8-ccfd-c199df411668"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "data=\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n",
            "263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soPGVheskaQP"
      },
      "source": [
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXYPQZKPx0UB",
        "outputId": "f920289b-120c-4529-b322-217f8259bb51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "xs.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(453, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJtwVB2NbOAP",
        "outputId": "513d9390-8591-477b-da7a-190598e1b98d"
      },
      "source": [
        "print(tokenizer.word_index['in'])\n",
        "print(tokenizer.word_index['the'])\n",
        "print(tokenizer.word_index['town'])\n",
        "print(tokenizer.word_index['of'])\n",
        "print(tokenizer.word_index['athy'])\n",
        "print(tokenizer.word_index['one'])\n",
        "print(tokenizer.word_index['jeremy'])\n",
        "print(tokenizer.word_index['lanigan'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "2\n",
            "66\n",
            "8\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49Cv68JOakwv",
        "outputId": "a7b3d428-7176-4d96-bd1a-07bf87354031"
      },
      "source": [
        "print(xs[6])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  4  2 66  8 67 68 69]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY-jwvfgbEF8",
        "outputId": "f4dda162-84a4-4a65-c790-81e476b9d15f"
      },
      "source": [
        "print(ys[6])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtzlUMYadhKt",
        "outputId": "8a0b99bc-bbb4-441e-fe2b-693d348ed2d5"
      },
      "source": [
        "print(xs[5])\n",
        "print(ys[5])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  0  4  2 66  8 67 68]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4myRpB1c4Gg",
        "outputId": "cf2f86d7-02c2-456d-d515-a91a1d5a5d20"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R27DYSBRxOv6"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\r\n",
        "    def on_epoch_end(self, epoch, logs={}):\r\n",
        "        if logs.get('accuracy') > 0.95:\r\n",
        "            print('\\nTraining accuracy reached more than 95%. Training terminated')\r\n",
        "            self.model.stop_training = True\r\n",
        "\r\n",
        "callback = myCallback()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9vH8Y59ajYL",
        "outputId": "7ddb7f2f-a7d3-4ae2-8c16-f8a9b64e43c3"
      },
      "source": [
        "model = Sequential(name='course3_week4_lesson1_model')\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(xs, ys, epochs=500, verbose=1, callbacks=[callback])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 2s 7ms/step - loss: 5.5689 - accuracy: 0.0392\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.5441 - accuracy: 0.0579\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.5015 - accuracy: 0.0549\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.3521 - accuracy: 0.0608\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.1477 - accuracy: 0.0454\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.0152 - accuracy: 0.0442\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.9852 - accuracy: 0.0497\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.0013 - accuracy: 0.0848\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.9125 - accuracy: 0.0662\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.9331 - accuracy: 0.0539\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.8478 - accuracy: 0.0784\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.9176 - accuracy: 0.0639\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.8059 - accuracy: 0.0527\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.6972 - accuracy: 0.0650\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.6593 - accuracy: 0.0662\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.5963 - accuracy: 0.1097\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.5241 - accuracy: 0.0981\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.4850 - accuracy: 0.1096\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.3912 - accuracy: 0.1165\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.2791 - accuracy: 0.1402\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.3400 - accuracy: 0.1454\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.2449 - accuracy: 0.1210\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.2613 - accuracy: 0.1301\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.1075 - accuracy: 0.1513\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.1673 - accuracy: 0.1339\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.0150 - accuracy: 0.1518\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.0340 - accuracy: 0.1521\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.9311 - accuracy: 0.1615\n",
            "Epoch 29/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.9086 - accuracy: 0.1607\n",
            "Epoch 30/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.9116 - accuracy: 0.1738\n",
            "Epoch 31/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.8398 - accuracy: 0.1783\n",
            "Epoch 32/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.8131 - accuracy: 0.1724\n",
            "Epoch 33/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.7995 - accuracy: 0.1758\n",
            "Epoch 34/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.7672 - accuracy: 0.1929\n",
            "Epoch 35/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.6525 - accuracy: 0.2098\n",
            "Epoch 36/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.6770 - accuracy: 0.2149\n",
            "Epoch 37/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.6807 - accuracy: 0.2178\n",
            "Epoch 38/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.6075 - accuracy: 0.2083\n",
            "Epoch 39/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.5355 - accuracy: 0.2601\n",
            "Epoch 40/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.4358 - accuracy: 0.2617\n",
            "Epoch 41/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.5025 - accuracy: 0.2614\n",
            "Epoch 42/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.4442 - accuracy: 0.2845\n",
            "Epoch 43/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.3875 - accuracy: 0.2761\n",
            "Epoch 44/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.3724 - accuracy: 0.2440\n",
            "Epoch 45/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.3231 - accuracy: 0.2856\n",
            "Epoch 46/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.2364 - accuracy: 0.2905\n",
            "Epoch 47/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.2275 - accuracy: 0.2889\n",
            "Epoch 48/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.1819 - accuracy: 0.2976\n",
            "Epoch 49/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.1086 - accuracy: 0.3228\n",
            "Epoch 50/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.1687 - accuracy: 0.2863\n",
            "Epoch 51/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.1414 - accuracy: 0.3352\n",
            "Epoch 52/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.1303 - accuracy: 0.3357\n",
            "Epoch 53/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.1045 - accuracy: 0.3333\n",
            "Epoch 54/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.0107 - accuracy: 0.3697\n",
            "Epoch 55/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.9311 - accuracy: 0.3956\n",
            "Epoch 56/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.8865 - accuracy: 0.3976\n",
            "Epoch 57/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.9019 - accuracy: 0.3887\n",
            "Epoch 58/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.8258 - accuracy: 0.4350\n",
            "Epoch 59/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.8418 - accuracy: 0.4227\n",
            "Epoch 60/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.7052 - accuracy: 0.4679\n",
            "Epoch 61/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.7708 - accuracy: 0.4364\n",
            "Epoch 62/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.7690 - accuracy: 0.4459\n",
            "Epoch 63/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.7275 - accuracy: 0.4792\n",
            "Epoch 64/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.6235 - accuracy: 0.4968\n",
            "Epoch 65/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.6666 - accuracy: 0.4863\n",
            "Epoch 66/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.5917 - accuracy: 0.4648\n",
            "Epoch 67/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.5859 - accuracy: 0.5090\n",
            "Epoch 68/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.5038 - accuracy: 0.5244\n",
            "Epoch 69/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.4687 - accuracy: 0.5236\n",
            "Epoch 70/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.5999 - accuracy: 0.5139\n",
            "Epoch 71/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.4577 - accuracy: 0.5447\n",
            "Epoch 72/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.4407 - accuracy: 0.5425\n",
            "Epoch 73/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.4234 - accuracy: 0.5681\n",
            "Epoch 74/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.3636 - accuracy: 0.5701\n",
            "Epoch 75/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3621 - accuracy: 0.5478\n",
            "Epoch 76/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3826 - accuracy: 0.5375\n",
            "Epoch 77/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2418 - accuracy: 0.6072\n",
            "Epoch 78/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2781 - accuracy: 0.5654\n",
            "Epoch 79/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3450 - accuracy: 0.5461\n",
            "Epoch 80/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2482 - accuracy: 0.5895\n",
            "Epoch 81/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2323 - accuracy: 0.5789\n",
            "Epoch 82/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.1360 - accuracy: 0.5921\n",
            "Epoch 83/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.1462 - accuracy: 0.5894\n",
            "Epoch 84/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2022 - accuracy: 0.5809\n",
            "Epoch 85/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2430 - accuracy: 0.5653\n",
            "Epoch 86/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.1040 - accuracy: 0.6036\n",
            "Epoch 87/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.0551 - accuracy: 0.6575\n",
            "Epoch 88/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.9963 - accuracy: 0.6397\n",
            "Epoch 89/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.9538 - accuracy: 0.6424\n",
            "Epoch 90/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.9911 - accuracy: 0.6501\n",
            "Epoch 91/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.9799 - accuracy: 0.6266\n",
            "Epoch 92/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.9841 - accuracy: 0.6527\n",
            "Epoch 93/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.9908 - accuracy: 0.6326\n",
            "Epoch 94/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.9986 - accuracy: 0.6499\n",
            "Epoch 95/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.9367 - accuracy: 0.6649\n",
            "Epoch 96/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.9129 - accuracy: 0.6821\n",
            "Epoch 97/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.8286 - accuracy: 0.6831\n",
            "Epoch 98/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.8563 - accuracy: 0.6818\n",
            "Epoch 99/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.8015 - accuracy: 0.6999\n",
            "Epoch 100/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.7687 - accuracy: 0.6874\n",
            "Epoch 101/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.7183 - accuracy: 0.7217\n",
            "Epoch 102/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.7103 - accuracy: 0.7091\n",
            "Epoch 103/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.7274 - accuracy: 0.7222\n",
            "Epoch 104/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.8516 - accuracy: 0.6646\n",
            "Epoch 105/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.7239 - accuracy: 0.7246\n",
            "Epoch 106/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.6213 - accuracy: 0.7490\n",
            "Epoch 107/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6375 - accuracy: 0.7325\n",
            "Epoch 108/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.5719 - accuracy: 0.7716\n",
            "Epoch 109/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.5936 - accuracy: 0.7807\n",
            "Epoch 110/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5904 - accuracy: 0.7577\n",
            "Epoch 111/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6296 - accuracy: 0.7529\n",
            "Epoch 112/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.5978 - accuracy: 0.7319\n",
            "Epoch 113/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.5334 - accuracy: 0.7702\n",
            "Epoch 114/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5668 - accuracy: 0.7586\n",
            "Epoch 115/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5628 - accuracy: 0.7481\n",
            "Epoch 116/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4917 - accuracy: 0.7557\n",
            "Epoch 117/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5206 - accuracy: 0.7555\n",
            "Epoch 118/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5477 - accuracy: 0.7630\n",
            "Epoch 119/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.4120 - accuracy: 0.8051\n",
            "Epoch 120/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4800 - accuracy: 0.7314\n",
            "Epoch 121/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4152 - accuracy: 0.7700\n",
            "Epoch 122/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.4453 - accuracy: 0.7643\n",
            "Epoch 123/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3624 - accuracy: 0.7993\n",
            "Epoch 124/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3816 - accuracy: 0.8055\n",
            "Epoch 125/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3570 - accuracy: 0.7938\n",
            "Epoch 126/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3936 - accuracy: 0.7998\n",
            "Epoch 127/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3654 - accuracy: 0.8110\n",
            "Epoch 128/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3854 - accuracy: 0.7790\n",
            "Epoch 129/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3486 - accuracy: 0.8238\n",
            "Epoch 130/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2858 - accuracy: 0.8210\n",
            "Epoch 131/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2206 - accuracy: 0.8211\n",
            "Epoch 132/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2566 - accuracy: 0.8501\n",
            "Epoch 133/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2271 - accuracy: 0.8436\n",
            "Epoch 134/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2696 - accuracy: 0.8277\n",
            "Epoch 135/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2502 - accuracy: 0.8497\n",
            "Epoch 136/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1993 - accuracy: 0.8362\n",
            "Epoch 137/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1771 - accuracy: 0.8404\n",
            "Epoch 138/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2193 - accuracy: 0.8505\n",
            "Epoch 139/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1800 - accuracy: 0.8490\n",
            "Epoch 140/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1363 - accuracy: 0.8620\n",
            "Epoch 141/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1115 - accuracy: 0.8713\n",
            "Epoch 142/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1605 - accuracy: 0.8388\n",
            "Epoch 143/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1148 - accuracy: 0.8526\n",
            "Epoch 144/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0872 - accuracy: 0.8612\n",
            "Epoch 145/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0892 - accuracy: 0.8651\n",
            "Epoch 146/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1189 - accuracy: 0.8607\n",
            "Epoch 147/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0605 - accuracy: 0.8479\n",
            "Epoch 148/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0803 - accuracy: 0.8540\n",
            "Epoch 149/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0780 - accuracy: 0.8755\n",
            "Epoch 150/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0144 - accuracy: 0.8904\n",
            "Epoch 151/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0285 - accuracy: 0.8798\n",
            "Epoch 152/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0177 - accuracy: 0.8491\n",
            "Epoch 153/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0374 - accuracy: 0.8622\n",
            "Epoch 154/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0198 - accuracy: 0.8710\n",
            "Epoch 155/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.9974 - accuracy: 0.8817\n",
            "Epoch 156/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.9818 - accuracy: 0.8722\n",
            "Epoch 157/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.0362 - accuracy: 0.8480\n",
            "Epoch 158/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.9900 - accuracy: 0.8629\n",
            "Epoch 159/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0108 - accuracy: 0.8612\n",
            "Epoch 160/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.9504 - accuracy: 0.8776\n",
            "Epoch 161/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9501 - accuracy: 0.9001\n",
            "Epoch 162/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.9615 - accuracy: 0.8618\n",
            "Epoch 163/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8976 - accuracy: 0.8944\n",
            "Epoch 164/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.9647 - accuracy: 0.8756\n",
            "Epoch 165/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.9674 - accuracy: 0.8694\n",
            "Epoch 166/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.9487 - accuracy: 0.8621\n",
            "Epoch 167/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.9514 - accuracy: 0.8655\n",
            "Epoch 168/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8939 - accuracy: 0.8909\n",
            "Epoch 169/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.9162 - accuracy: 0.8816\n",
            "Epoch 170/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8397 - accuracy: 0.8987\n",
            "Epoch 171/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8657 - accuracy: 0.8788\n",
            "Epoch 172/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.8541 - accuracy: 0.8973\n",
            "Epoch 173/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7679 - accuracy: 0.9233\n",
            "Epoch 174/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8199 - accuracy: 0.8910\n",
            "Epoch 175/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8208 - accuracy: 0.8963\n",
            "Epoch 176/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8243 - accuracy: 0.8941\n",
            "Epoch 177/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8555 - accuracy: 0.8807\n",
            "Epoch 178/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8058 - accuracy: 0.9070\n",
            "Epoch 179/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8135 - accuracy: 0.9074\n",
            "Epoch 180/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7718 - accuracy: 0.9099\n",
            "Epoch 181/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7796 - accuracy: 0.8977\n",
            "Epoch 182/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7470 - accuracy: 0.9140\n",
            "Epoch 183/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7475 - accuracy: 0.9029\n",
            "Epoch 184/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7806 - accuracy: 0.8895\n",
            "Epoch 185/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7543 - accuracy: 0.9038\n",
            "Epoch 186/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7278 - accuracy: 0.9142\n",
            "Epoch 187/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6876 - accuracy: 0.9252\n",
            "Epoch 188/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6630 - accuracy: 0.9162\n",
            "Epoch 189/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6705 - accuracy: 0.9311\n",
            "Epoch 190/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6791 - accuracy: 0.9254\n",
            "Epoch 191/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6765 - accuracy: 0.9314\n",
            "Epoch 192/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6714 - accuracy: 0.9235\n",
            "Epoch 193/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6773 - accuracy: 0.9076\n",
            "Epoch 194/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6591 - accuracy: 0.9092\n",
            "Epoch 195/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6713 - accuracy: 0.9074\n",
            "Epoch 196/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7195 - accuracy: 0.8941\n",
            "Epoch 197/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7475 - accuracy: 0.8815\n",
            "Epoch 198/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7241 - accuracy: 0.8861\n",
            "Epoch 199/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6676 - accuracy: 0.8962\n",
            "Epoch 200/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6723 - accuracy: 0.8996\n",
            "Epoch 201/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7244 - accuracy: 0.8945\n",
            "Epoch 202/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6366 - accuracy: 0.9256\n",
            "Epoch 203/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6456 - accuracy: 0.9222\n",
            "Epoch 204/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6082 - accuracy: 0.9089\n",
            "Epoch 205/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6171 - accuracy: 0.9145\n",
            "Epoch 206/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5738 - accuracy: 0.9378\n",
            "Epoch 207/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6287 - accuracy: 0.9195\n",
            "Epoch 208/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6371 - accuracy: 0.9121\n",
            "Epoch 209/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5682 - accuracy: 0.9362\n",
            "Epoch 210/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5484 - accuracy: 0.9405\n",
            "Epoch 211/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5563 - accuracy: 0.9542\n",
            "Epoch 212/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5263 - accuracy: 0.9572\n",
            "Epoch 213/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5721 - accuracy: 0.9370\n",
            "Epoch 214/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5398 - accuracy: 0.9222\n",
            "Epoch 215/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5614 - accuracy: 0.9119\n",
            "Epoch 216/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5596 - accuracy: 0.9116\n",
            "Epoch 217/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5399 - accuracy: 0.9427\n",
            "Epoch 218/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5252 - accuracy: 0.9328\n",
            "Epoch 219/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5303 - accuracy: 0.9367\n",
            "Epoch 220/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4721 - accuracy: 0.9559\n",
            "Epoch 221/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5145 - accuracy: 0.9255\n",
            "Epoch 222/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5167 - accuracy: 0.9337\n",
            "Epoch 223/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4875 - accuracy: 0.9349\n",
            "Epoch 224/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4836 - accuracy: 0.9481\n",
            "Epoch 225/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5007 - accuracy: 0.9272\n",
            "Epoch 226/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4998 - accuracy: 0.9406\n",
            "Epoch 227/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5525 - accuracy: 0.9249\n",
            "Epoch 228/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.9469\n",
            "Epoch 229/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4728 - accuracy: 0.9387\n",
            "Epoch 230/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4666 - accuracy: 0.9381\n",
            "Epoch 231/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5132 - accuracy: 0.9245\n",
            "Epoch 232/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4776 - accuracy: 0.9360\n",
            "Epoch 233/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4937 - accuracy: 0.9296\n",
            "Epoch 234/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4452 - accuracy: 0.9536\n",
            "Epoch 235/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4461 - accuracy: 0.9462\n",
            "Epoch 236/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4720 - accuracy: 0.9317\n",
            "Epoch 237/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.9284\n",
            "Epoch 238/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.9409\n",
            "Epoch 239/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.9603\n",
            "Epoch 240/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4341 - accuracy: 0.9578\n",
            "Epoch 241/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.9495\n",
            "Epoch 242/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.9520\n",
            "Epoch 243/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4156 - accuracy: 0.9532\n",
            "Epoch 244/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.9524\n",
            "Epoch 245/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4379 - accuracy: 0.9336\n",
            "Epoch 246/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.9275\n",
            "Epoch 247/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.9527\n",
            "Epoch 248/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4144 - accuracy: 0.9424\n",
            "Epoch 249/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3906 - accuracy: 0.9453\n",
            "Epoch 250/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3673 - accuracy: 0.9561\n",
            "Epoch 251/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3894 - accuracy: 0.9497\n",
            "Epoch 252/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.9375\n",
            "Epoch 253/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3865 - accuracy: 0.9424\n",
            "Epoch 254/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3865 - accuracy: 0.9371\n",
            "Epoch 255/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.9527\n",
            "Epoch 256/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3616 - accuracy: 0.9482\n",
            "Epoch 257/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3672 - accuracy: 0.9577\n",
            "Epoch 258/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3652 - accuracy: 0.9474\n",
            "Epoch 259/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3409 - accuracy: 0.9577\n",
            "Epoch 260/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3554 - accuracy: 0.9485\n",
            "Epoch 261/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3871 - accuracy: 0.9383\n",
            "Epoch 262/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3646 - accuracy: 0.9401\n",
            "Epoch 263/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3332 - accuracy: 0.9444\n",
            "Epoch 264/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3529 - accuracy: 0.9481\n",
            "Epoch 265/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3483 - accuracy: 0.9457\n",
            "Epoch 266/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3423 - accuracy: 0.9504\n",
            "Epoch 267/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3446 - accuracy: 0.9441\n",
            "Epoch 268/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3411 - accuracy: 0.9409\n",
            "Epoch 269/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3539 - accuracy: 0.9343\n",
            "Epoch 270/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3374 - accuracy: 0.9416\n",
            "Epoch 271/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3337 - accuracy: 0.9407\n",
            "Epoch 272/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3467 - accuracy: 0.9438\n",
            "Epoch 273/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3652 - accuracy: 0.9258\n",
            "Epoch 274/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3623 - accuracy: 0.9277\n",
            "Epoch 275/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3360 - accuracy: 0.9406\n",
            "Epoch 276/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3351 - accuracy: 0.9305\n",
            "Epoch 277/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3233 - accuracy: 0.9421\n",
            "Epoch 278/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3235 - accuracy: 0.9384\n",
            "Epoch 279/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3293 - accuracy: 0.9390\n",
            "Epoch 280/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2982 - accuracy: 0.9517\n",
            "Epoch 281/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3196 - accuracy: 0.9416\n",
            "Epoch 282/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3152 - accuracy: 0.9510\n",
            "Epoch 283/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3017 - accuracy: 0.9602\n",
            "Epoch 284/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2819 - accuracy: 0.9615\n",
            "Epoch 285/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3198 - accuracy: 0.9335\n",
            "Epoch 286/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2986 - accuracy: 0.9422\n",
            "Epoch 287/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2802 - accuracy: 0.9591\n",
            "Epoch 288/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2874 - accuracy: 0.9471\n",
            "Epoch 289/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2791 - accuracy: 0.9537\n",
            "\n",
            "Training accuracy reached more than 95%. Training terminated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YXGelKThoTT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "poeprYK8h-c7",
        "outputId": "63089438-36c3-4173-feee-9ff98ef7c3f4"
      },
      "source": [
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vc6PHgxa6Hm",
        "outputId": "75821aa6-1b46-419e-d605-56d72df40f4e"
      },
      "source": [
        "seed_text = \"Laurence went to dublin\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Laurence went to dublin as merry as as a rose hall hall table three new her for ball ball ball a reel and a jig mccarthy make lanigan glisten glisten glisten hall suppose them creature new ball and ask your eyes suppose we hall old hall hall hall hall strangled punch stepped long for to ground give her out and cried was bacon and tea tea meelia murther lanigan hall hall replied steps steps weeks spent learn banished their nonsense nonsense nonsense nonsense nonsense hearty suppose their free invitation glisten glisten glisten hall hall ground three how got all all entangled entangled they were\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}